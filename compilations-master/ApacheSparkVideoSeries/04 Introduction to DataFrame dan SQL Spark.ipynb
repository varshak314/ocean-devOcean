{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading File Data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+----------------+------+-------+\n",
      "|      Date| Time|      City|            Item| Total|Payment|\n",
      "+----------+-----+----------+----------------+------+-------+\n",
      "|2012-01-01|09:00|  San Jose|  Men's Clothing|214.05|   Amex|\n",
      "|2012-01-01|09:00|Fort Worth|Women's Clothing|153.57|   Visa|\n",
      "|2012-01-01|09:00| San Diego|           Music| 66.08|   Cash|\n",
      "+----------+-----+----------+----------------+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import module\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "#create session in order to be capable of accessing all Spark API\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Introdution to Spark DataFrame\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#define data schema for file we want to read\n",
    "purchaseSchema = StructType([\n",
    "    StructField(\"Date\", DateType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Item\", StringType(), True),\n",
    "    StructField(\"Total\", FloatType(), True),\n",
    "    StructField(\"Payment\", StringType(), True),\n",
    "])    \n",
    "\n",
    "# read csv file with our defined schema into Spark DataFrame, and use \"tab\" delimiter\n",
    "purchaseDataframe = spark.read.csv(\n",
    "    \"dataset/purchases.csv\", \n",
    "    header=True, schema=purchaseSchema, sep=\"\\t\")\n",
    "#show 3 rows of our DataFrame\n",
    "purchaseDataframe.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting number of rows, printing dataframe schema and printing statistic of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows:  4138476\n",
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Total: float (nullable = true)\n",
      " |-- Payment: string (nullable = true)\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|             Total|\n",
      "+-------+------------------+\n",
      "|  count|           4138476|\n",
      "|   mean|249.96108549398525|\n",
      "| stddev| 144.3174111542959|\n",
      "|    min|               0.0|\n",
      "|    max|            499.99|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count number of rows of our dataFrame\n",
    "num_rows = purchaseDataframe.count()\n",
    "print(\"number of rows: \", num_rows)\n",
    "#show our dataFrame schema\n",
    "purchaseDataframe.printSchema()\n",
    "#show statistic of the data we want\n",
    "purchaseDataframe.describe('Total').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new dataFrame from a subset of our existing dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      City| Total|\n",
      "+----------+------+\n",
      "|  San Jose|214.05|\n",
      "|Fort Worth|153.57|\n",
      "| San Diego| 66.08|\n",
      "+----------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- Total: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create new dataFrame from \"City\" and \"Total\" columns\n",
    "newDataframe = purchaseDataframe.select(purchaseDataframe['City'], \n",
    "                                              purchaseDataframe['Total'])\n",
    "newDataframe.show(3); #menampilkan 3 baris DataFrame baru kita\n",
    "newDataframe.printSchema() #print skema dari DataFrame baru kita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a constant value to every row data in certain column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|      City|(Total + 10)|\n",
      "+----------+------------+\n",
      "|  San Jose|      224.05|\n",
      "|Fort Worth|      163.57|\n",
      "| San Diego|       76.08|\n",
      "+----------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#adding constant value of 10 to every row data in \"Total\" column\n",
    "purchaseDataframe.select(purchaseDataframe['City'],\n",
    "                         purchaseDataframe['Total']+10).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering dataFrame using our defined condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------------------+------+----------+\n",
      "|      Date| Time|      City|               Item| Total|   Payment|\n",
      "+----------+-----+----------+-------------------+------+----------+\n",
      "|2012-01-01|09:00|  San Jose|     Men's Clothing|214.05|      Amex|\n",
      "|2012-01-01|09:00|Pittsburgh|       Pet Supplies|493.51|  Discover|\n",
      "|2012-01-01|09:00|     Omaha|Children's Clothing|235.63|MasterCard|\n",
      "+----------+-----+----------+-------------------+------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter only row data whose \"Total\" column value > 200\n",
    "purchaseDataframe.filter(purchaseDataframe['Total'] > 200).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting dataFrame by certain column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+----------------+------+----------+\n",
      "|      Date| Time|       City|            Item| Total|   Payment|\n",
      "+----------+-----+-----------+----------------+------+----------+\n",
      "|2012-10-07|11:11|Albuquerque|    Pet Supplies| 308.7|      Visa|\n",
      "|2012-10-07|11:40|Albuquerque|            Toys|299.63|MasterCard|\n",
      "|2012-10-07|11:13|Albuquerque|Women's Clothing|419.49|  Discover|\n",
      "|2012-10-07|10:39|Albuquerque|    Pet Supplies| 401.3|MasterCard|\n",
      "+----------+-----+-----------+----------------+------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sortedByCity = purchaseDataframe.orderBy('City').show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating number of transactions in each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|           City|count|\n",
      "+---------------+-----+\n",
      "|North Las Vegas|40013|\n",
      "|        Phoenix|40333|\n",
      "|          Omaha|40209|\n",
      "|      Anchorage|39806|\n",
      "|        Anaheim|40086|\n",
      "+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numTransactionEachCity = purchaseDataframe.groupBy(\"City\").count()\n",
    "numTransactionEachCity.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Accessing DataFrame\n",
    "Since Spark dataFrame is distributed into clusters, we cannot access it by [row,column] as in pandas dataFrame for example. There is an alternative way to do that by creating new column with \"incremental ID\". Then, we can access by row using \".filter()\" function to our \"incremental ID\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------------------+------+----------+-----+\n",
      "|      Date| Time|      City|               Item| Total|   Payment|index|\n",
      "+----------+-----+----------+-------------------+------+----------+-----+\n",
      "|2012-01-01|09:00|  San Jose|     Men's Clothing|214.05|      Amex|    0|\n",
      "|2012-01-01|09:00|Fort Worth|   Women's Clothing|153.57|      Visa|    1|\n",
      "|2012-01-01|09:00| San Diego|              Music| 66.08|      Cash|    2|\n",
      "|2012-01-01|09:00|Pittsburgh|       Pet Supplies|493.51|  Discover|    3|\n",
      "|2012-01-01|09:00|     Omaha|Children's Clothing|235.63|MasterCard|    4|\n",
      "|2012-01-01|09:00|  Stockton|     Men's Clothing|247.18|MasterCard|    5|\n",
      "|2012-01-01|09:00|    Austin|            Cameras| 379.6|      Visa|    6|\n",
      "+----------+-----+----------+-------------------+------+----------+-----+\n",
      "only showing top 7 rows\n",
      "\n",
      "+----------+-----+----------+-------------------+------+----------+-----+\n",
      "|      Date| Time|      City|               Item| Total|   Payment|index|\n",
      "+----------+-----+----------+-------------------+------+----------+-----+\n",
      "|2012-01-01|09:00| San Diego|              Music| 66.08|      Cash|    2|\n",
      "|2012-01-01|09:00|Pittsburgh|       Pet Supplies|493.51|  Discover|    3|\n",
      "|2012-01-01|09:00|     Omaha|Children's Clothing|235.63|MasterCard|    4|\n",
      "+----------+-----+----------+-------------------+------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import monotonically_increasing_id\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "newPurchasedDataframe = purchaseDataframe.withColumn(\n",
    "    \"index\", monotonically_increasing_id())\n",
    "newPurchasedDataframe.show(7)\n",
    "row2Till4 = newPurchasedDataframe.filter((newPurchasedDataframe['index']>=2) &\n",
    "                                         (newPurchasedDataframe['index']<=4))\n",
    "row2Till4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to access it by row and column, use \".select()\" function we ever used above before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Total|\n",
      "+-----+\n",
      "|66.08|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataRow2ColumnTotal = newPurchasedDataframe.filter(newPurchasedDataframe['index']==2).select('Total')\n",
    "dataRow2ColumnTotal.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SQL query in dataFrame\n",
    "\n",
    "Create a new dataFrame from the subset of our existing dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "| Total|Payment|\n",
      "+------+-------+\n",
      "|214.05|   Amex|\n",
      "|153.57|   Visa|\n",
      "| 66.08|   Cash|\n",
      "+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#we need to make sql temporary view for our dataFrame\n",
    "purchaseDataframe.createOrReplaceTempView(\"purchaseSql\")\n",
    "\n",
    "#select \"Total\" dan \"Payment\" column from our sql temporary view\n",
    "anotherNewDataframe = spark.sql(\"SELECT Total, Payment FROM purchaseSql\")\n",
    "anotherNewDataframe.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting data by certain column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+----------------+------+----------+\n",
      "|      Date| Time|       City|            Item| Total|   Payment|\n",
      "+----------+-----+-----------+----------------+------+----------+\n",
      "|2012-10-07|11:11|Albuquerque|    Pet Supplies| 308.7|      Visa|\n",
      "|2012-10-07|11:41|Albuquerque|           Music|365.64|      Visa|\n",
      "|2012-10-07|11:13|Albuquerque|Women's Clothing|419.49|  Discover|\n",
      "|2012-10-07|10:39|Albuquerque|    Pet Supplies| 401.3|MasterCard|\n",
      "|2012-10-07|11:18|Albuquerque|          Crafts|475.77|      Visa|\n",
      "+----------+-----+-----------+----------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sorting data by \"City\" column alphabetically\n",
    "orderByCity = spark.sql(\"SELECT * FROM purchaseSql ORDER BY City\")\n",
    "orderByCity.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last one, we wil show how to filter data with \"Total\" column value > 200, and sort them by \"Payment\" column data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------+-------------------+------+-------+\n",
      "|      Date| Time|          City|               Item| Total|Payment|\n",
      "+----------+-----+--------------+-------------------+------+-------+\n",
      "|2012-10-07|10:34|      Richmond|Children's Clothing|252.45|   Amex|\n",
      "|2012-10-07|10:36|San Bernardino|               Toys|272.91|   Amex|\n",
      "|2012-10-07|10:34|     Baltimore|              Books|299.94|   Amex|\n",
      "|2012-10-07|10:33|       Lincoln|       Pet Supplies|359.44|   Amex|\n",
      "+----------+-----+--------------+-------------------+------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter nilai kolom Total>50 dan urutkan berdasarkan cara pembayaran\n",
    "filterAndSortWithSQL = spark.sql(\"SELECT * FROM purchaseSql WHERE Total>200 ORDER BY Payment\")\n",
    "filterAndSortWithSQL.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
